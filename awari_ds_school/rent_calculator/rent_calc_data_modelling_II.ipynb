{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "false-requirement",
   "metadata": {},
   "source": [
    "# Rent Calculator - Data Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informational-badge",
   "metadata": {},
   "source": [
    "### Data Acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "violent-peripheral",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from urllib.error import HTTPError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "reliable-philip",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aluguel</th>\n",
       "      <th>quartos</th>\n",
       "      <th>banheiro</th>\n",
       "      <th>vaga</th>\n",
       "      <th>area</th>\n",
       "      <th>zona</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3400</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>130</td>\n",
       "      <td>Oeste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3400</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>88</td>\n",
       "      <td>Oeste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5400</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>72</td>\n",
       "      <td>Oeste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2600</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>91</td>\n",
       "      <td>Oeste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3800</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44</td>\n",
       "      <td>Oeste</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   aluguel  quartos  banheiro  vaga  area   zona\n",
       "0     3400      2.0       2.0   1.0   130  Oeste\n",
       "1     3400      2.0       2.0   2.0    88  Oeste\n",
       "2     5400      2.0       2.0   1.0    72  Oeste\n",
       "3     2600      2.0       2.0   1.0    91  Oeste\n",
       "4     3800      1.0       1.0   1.0    44  Oeste"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get csv\n",
    "columns = ['rent', 'rooms', 'bathrooms', 'parking', 'area', 'zone']\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv('https://raw.githubusercontent.com/smalvar/CalculadoraAluguel-Novembro/main/banco_final.csv',\n",
    "                    usecols=['aluguel', 'quartos', 'banheiro', 'vaga', 'area', 'zona'])\n",
    "    # df2 = pd.read_csv('https://raw.githubusercontent.com/smalvar/CalculadoraAluguel-Novembro/main/banco_final.csv')\n",
    "except HTTPError as e_http:\n",
    "    print('HTTP Error: {e_http.code}')\n",
    "    \n",
    "#df.columns = columns\n",
    "#df.reset_index(drop=True, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "missing-jesus",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_zone(zone: str) -> str:\n",
    "    '''Translates a zone to English'''\n",
    "    if zone == 'Oeste':\n",
    "        return 'West'\n",
    "    elif zone == 'Leste':\n",
    "        return 'East'\n",
    "    elif zone == 'Sul':\n",
    "        return 'South'\n",
    "    elif zone == 'Norte':\n",
    "        return 'North'\n",
    "    elif zone == 'Centro':\n",
    "        return 'CBD'\n",
    "    else:\n",
    "        raise ValueError('Invalid zone.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "activated-maker",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map the zones to English equivalent\n",
    "#df.zone = df.zone.map(translate_zone)\n",
    "#df.zone.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focused-discount",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "individual-morning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test data\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "convinced-carolina",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.25, random_state=1, stratify=df['zona'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "solid-wildlife",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aluguel</th>\n",
       "      <th>quartos</th>\n",
       "      <th>banheiro</th>\n",
       "      <th>vaga</th>\n",
       "      <th>area</th>\n",
       "      <th>zona</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>15000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>464</td>\n",
       "      <td>Sul</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>7000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>169</td>\n",
       "      <td>Sul</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>8000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>280</td>\n",
       "      <td>Oeste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>850</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98</td>\n",
       "      <td>Leste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>6000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>Sul</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     aluguel  quartos  banheiro  vaga  area   zona\n",
       "504    15000      4.0       6.0   4.0   464    Sul\n",
       "397     7000      4.0       5.0   3.0   169    Sul\n",
       "74      8000      3.0       2.0   3.0   280  Oeste\n",
       "737      850      1.0       1.0   0.0    98  Leste\n",
       "477     6000      8.0       2.0   8.0  1000    Sul"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "apparent-newton",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-142e0a19dbb0>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['aluguel']=train['aluguel'].apply(np.log1p)\n",
      "<ipython-input-8-142e0a19dbb0>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['area']=train['area'].apply(np.log1p)\n",
      "<ipython-input-8-142e0a19dbb0>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test['aluguel']=test['aluguel'].apply(np.log1p)\n",
      "<ipython-input-8-142e0a19dbb0>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test['area']=test['area'].apply(np.log1p)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "train['aluguel']=train['aluguel'].apply(np.log1p)\n",
    "train['area']=train['area'].apply(np.log1p)\n",
    "test['aluguel']=test['aluguel'].apply(np.log1p)\n",
    "test['area']=test['area'].apply(np.log1p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "lyric-travel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dummies for the zone column\n",
    "X_cols=['zona', 'area', 'quartos','banheiro','vaga']\n",
    "y_col=['aluguel']\n",
    "\n",
    "X_train = train[X_cols]\n",
    "X_test = test[X_cols]\n",
    "y_train = train[y_col]\n",
    "y_test = test[y_col]\n",
    "\n",
    "X_train = pd.get_dummies(X_train)\n",
    "X_test = pd.get_dummies(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "convertible-adrian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>quartos</th>\n",
       "      <th>banheiro</th>\n",
       "      <th>vaga</th>\n",
       "      <th>zona_Centro</th>\n",
       "      <th>zona_Leste</th>\n",
       "      <th>zona_Norte</th>\n",
       "      <th>zona_Oeste</th>\n",
       "      <th>zona_Sul</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>6.142037</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>5.135798</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>5.638355</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>4.595120</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>6.908755</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         area  quartos  banheiro  vaga  zona_Centro  zona_Leste  zona_Norte  \\\n",
       "504  6.142037      4.0       6.0   4.0            0           0           0   \n",
       "397  5.135798      4.0       5.0   3.0            0           0           0   \n",
       "74   5.638355      3.0       2.0   3.0            0           0           0   \n",
       "737  4.595120      1.0       1.0   0.0            0           1           0   \n",
       "477  6.908755      8.0       2.0   8.0            0           0           0   \n",
       "\n",
       "     zona_Oeste  zona_Sul  \n",
       "504           0         1  \n",
       "397           0         1  \n",
       "74            1         0  \n",
       "737           0         0  \n",
       "477           0         1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floppy-south",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "sharing-projection",
   "metadata": {},
   "source": [
    "### KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "frank-sherman",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "neigh = KNeighborsRegressor()\n",
    "# train the model\n",
    "neigh.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "structured-bridges",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions for rent (y)\n",
    "y_pred = neigh.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "noticed-soccer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [7.76987168], Expected: aluguel\n"
     ]
    }
   ],
   "source": [
    "for p, e in zip(y_pred[::10], y_test[::10]):\n",
    "    print(f'Predicted: {p}, Expected: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "south-speaking",
   "metadata": {},
   "source": [
    "#### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aboriginal-evaluation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "hidden-sculpture",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5838446059869178"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Root Mean Square Error (RMSE)\n",
    "np.sqrt(np.mean((y_pred-y_test.values)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "polyphonic-reminder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34087452394001927"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean Squared Errorfrom\n",
    "np.mean((y_pred-y_test.values)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "continuous-consideration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44794482744682146"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean Absolute Error\n",
    "np.mean(np.abs(y_pred-y_test.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "canadian-clerk",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7209396684217904"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "advisory-gregory",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7533225177776965"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustained-sussex",
   "metadata": {},
   "source": [
    "### Testing with multiple models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "accepting-personality",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training KNeighborsRegressor\n",
      "Train score 0.7985911413749257\n",
      "Validation score [0.66945804 0.75771847 0.70358054 0.7286198  0.60056736]\n",
      "Test score 0.7209396684217904\n",
      "================================================================================\n",
      "Training LinearRegression\n",
      "Train score 0.7413310011623597\n",
      "Validation score [0.69283186 0.79287584 0.72278178 0.76214167 0.64519801]\n",
      "Test score 0.7533225177776965\n",
      "================================================================================\n",
      "Training DecisionTreeRegressor\n",
      "Train score 0.9758351645143398\n",
      "Validation score [0.5576097  0.59875958 0.62456905 0.43395393 0.61589144]\n",
      "Test score 0.6754666836537955\n",
      "================================================================================\n",
      "Training RandomForestRegressor\n",
      "Train score 0.9457146297692551\n",
      "Validation score [0.71465774 0.77252422 0.75317034 0.6971233  0.73926479]\n",
      "Test score 0.7817272989455956\n",
      "================================================================================\n",
      "Training XGBRegressor\n",
      "Train score 0.9630670799901603\n",
      "Validation score [0.66998745 0.7272265  0.70926709 0.63177362 0.69306454]\n",
      "Test score 0.7758716381640421\n",
      "================================================================================\n",
      "Training MLPRegressor\n",
      "Train score 0.7698213357672445\n",
      "Validation score [0.69496689 0.73799272 0.7392496  0.70783947 0.61395538]\n",
      "Test score 0.7738769233653229\n",
      "================================================================================\n",
      "Training LGBMRegressor\n",
      "Train score 0.8714710429834136\n",
      "Validation score [0.69145646 0.79641242 0.75525109 0.70439177 0.72388296]\n",
      "Test score 0.7826512355622455\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") # ignore warning\n",
    "\n",
    "# import sklearn Estimators\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "regressor_list = [ KNeighborsRegressor(),\n",
    "                  LinearRegression(),\n",
    "                  DecisionTreeRegressor(),\n",
    "                  RandomForestRegressor(),\n",
    "                  XGBRegressor(),\n",
    "                  MLPRegressor(),\n",
    "                  LGBMRegressor(),\n",
    "                  ]\n",
    "\n",
    "for reg in regressor_list:\n",
    "  print('Training', reg.__class__.__name__)\n",
    "  reg.fit(X_train, y_train)\n",
    "  train_score = reg.score(X_train, y_train)\n",
    "  val_score = cross_val_score(reg, X_train, y_train, cv=5)\n",
    "  test_score = reg.score(X_test, y_test)\n",
    "  print('Train score', train_score)\n",
    "  print('Validation score', val_score)\n",
    "  print('Test score', test_score)\n",
    "  print('='*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "executed-special",
   "metadata": {},
   "source": [
    "### Testing with XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "sorted-england",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=100, n_jobs=4, num_parallel_tree=1, random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBRegressor()\n",
    "xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "choice-photographer",
   "metadata": {},
   "source": [
    "### Using GriSearchCV to find the best parameters for the XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "sublime-bulgarian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None, gamma=None,\n",
       "                                    gpu_id=None, importance_type='gain',\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=None, max_delta_step=None,\n",
       "                                    max_depth=1, min_child_weight=None,\n",
       "                                    missing=nan, monotone_constraints=None,\n",
       "                                    n_estimators=100, n_jobs=None,\n",
       "                                    num_parallel_tree=None, random_state=None,\n",
       "                                    reg_alpha=None, reg_lambda=None,\n",
       "                                    scale_pos_weight=None, subsample=None,\n",
       "                                    tree_method=None, validate_parameters=None,\n",
       "                                    verbosity=None),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{'learning_rate': [0.1, 0.2, 0.3, 0.4],\n",
       "                          'max_depth': [3, 4, 5, 6, 7, 8],\n",
       "                          'n_estimators': [50, 100, 200]}],\n",
       "             scoring='r2')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters=[{'learning_rate':[0.1,0.2,0.3,0.4],\n",
    "             'max_depth':[3,4,5,6,7,8],\n",
    "             'n_estimators':[50, 100, 200]}]\n",
    "            \n",
    "xgb = XGBRegressor(n_estimators=100, max_depth=1)\n",
    "gs = GridSearchCV(xgb,parameters,scoring='r2',n_jobs=-1,cv=5)\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "refined-steering",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "structured-wrapping",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=50, n_jobs=4, num_parallel_tree=1, random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "intended-defendant",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = gs.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cardiovascular-hungary",
   "metadata": {},
   "source": [
    "#### Run model using the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dense-filename",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score 0.8045924988915034\n",
      "Validation score [0.74617778 0.7633818  0.73210872]\n",
      "Test score 0.7914393048009649\n"
     ]
    }
   ],
   "source": [
    "train_score = reg.score(X_train, y_train)\n",
    "val_score = cross_val_score(reg, X_train, y_train, cv=3)\n",
    "test_score = reg.score(X_test, y_test)\n",
    "print('Train score', train_score)\n",
    "print('Validation score', val_score)\n",
    "print('Test score', test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "adverse-confidence",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# now you can save it to a file\n",
    "with open('xgboost_regression.pkl', 'wb') as f:\n",
    "    pickle.dump(reg, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complex-charleston",
   "metadata": {},
   "source": [
    "### Testing all Estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "excellent-anchor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending ARDRegression\n",
      "Appending AdaBoostRegressor\n",
      "Appending BaggingRegressor\n",
      "Appending BayesianRidge\n",
      "Appending CCA\n",
      "Appending DecisionTreeRegressor\n",
      "Appending DummyRegressor\n",
      "Appending ElasticNet\n",
      "Appending ElasticNetCV\n",
      "Appending ExtraTreeRegressor\n",
      "Appending ExtraTreesRegressor\n",
      "Appending GammaRegressor\n",
      "Appending GaussianProcessRegressor\n",
      "Appending GradientBoostingRegressor\n",
      "Appending HistGradientBoostingRegressor\n",
      "Appending HuberRegressor\n",
      "Appending IsotonicRegression\n",
      "Appending KNeighborsRegressor\n",
      "Appending KernelRidge\n",
      "Appending Lars\n",
      "Appending LarsCV\n",
      "Appending Lasso\n",
      "Appending LassoCV\n",
      "Appending LassoLars\n",
      "Appending LassoLarsCV\n",
      "Appending LassoLarsIC\n",
      "Appending LinearRegression\n",
      "Appending LinearSVR\n",
      "Appending MLPRegressor\n",
      "Appending MultiOutputRegressor\n",
      "__init__() missing 1 required positional argument: 'estimator'\n",
      "Appending MultiTaskElasticNet\n",
      "Appending MultiTaskElasticNetCV\n",
      "Appending MultiTaskLasso\n",
      "Appending MultiTaskLassoCV\n",
      "Appending NuSVR\n",
      "Appending OrthogonalMatchingPursuit\n",
      "Appending OrthogonalMatchingPursuitCV\n",
      "Appending PLSCanonical\n",
      "Appending PLSRegression\n",
      "Appending PassiveAggressiveRegressor\n",
      "Appending PoissonRegressor\n",
      "Appending RANSACRegressor\n",
      "Appending RadiusNeighborsRegressor\n",
      "Appending RandomForestRegressor\n",
      "Appending RegressorChain\n",
      "__init__() missing 1 required positional argument: 'base_estimator'\n",
      "Appending Ridge\n",
      "Appending RidgeCV\n",
      "Appending SGDRegressor\n",
      "Appending SVR\n",
      "Appending StackingRegressor\n",
      "__init__() missing 1 required positional argument: 'estimators'\n",
      "Appending TheilSenRegressor\n",
      "Appending TransformedTargetRegressor\n",
      "Appending TweedieRegressor\n",
      "Appending VotingRegressor\n",
      "__init__() missing 1 required positional argument: 'estimators'\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import all_estimators\n",
    "\n",
    "estimators = all_estimators(type_filter='regressor')\n",
    "\n",
    "all_regs = []\n",
    "for name, RegressorClass in estimators:\n",
    "    try:\n",
    "        print('Appending', name)\n",
    "        reg = RegressorClass()\n",
    "        all_regs.append(reg)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "neither-tender",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinando ARDRegression\n",
      "Train score 0.7409320868670166\n",
      "Validation score [0.73752212 0.74464116 0.69679906]\n",
      "Test score 0.7513967418284355\n",
      "================================================================================\n",
      "Treinando AdaBoostRegressor\n",
      "Train score 0.7756446457436511\n",
      "Validation score [0.73579935 0.75645677 0.7198024 ]\n",
      "Test score 0.7755017670279257\n",
      "================================================================================\n",
      "Treinando BaggingRegressor\n",
      "Train score 0.9373329472822722\n",
      "Validation score [0.71015006 0.72971452 0.6866026 ]\n",
      "Test score 0.7597739233193238\n",
      "================================================================================\n",
      "Treinando BayesianRidge\n",
      "Train score 0.7412595218911704\n",
      "Validation score [0.73924346 0.73952322 0.69406951]\n",
      "Test score 0.7525237557882294\n",
      "================================================================================\n",
      "Treinando CCA\n",
      "Train score 2.4980018054066022e-14\n",
      "Validation score [-5.84323116e-05 -4.15321710e-03 -5.54408125e-03]\n",
      "Test score -0.0013093542476898534\n",
      "================================================================================\n",
      "Treinando DecisionTreeRegressor\n",
      "Train score 0.9758351645143398\n",
      "Validation score [0.53676094 0.53857147 0.54499831]\n",
      "Test score 0.6631638489778463\n",
      "================================================================================\n",
      "Treinando DummyRegressor\n",
      "Train score 0.0\n",
      "Validation score [-5.84323116e-05 -4.15321710e-03 -5.54408125e-03]\n",
      "Test score -0.001309354247712946\n",
      "================================================================================\n",
      "Treinando ElasticNet\n",
      "Train score 0.5199369211585149\n",
      "Validation score [0.50630055 0.55223271 0.49009927]\n",
      "Test score 0.47757608506578453\n",
      "================================================================================\n",
      "Treinando ElasticNetCV\n",
      "Train score 0.7410667369682908\n",
      "Validation score [0.73581586 0.74379029 0.69400522]\n",
      "Test score 0.7522025736922537\n",
      "================================================================================\n",
      "Treinando ExtraTreeRegressor\n",
      "Train score 0.9758351645143398\n",
      "Validation score [0.58163859 0.65265107 0.55149712]\n",
      "Test score 0.6769131981796046\n",
      "================================================================================\n",
      "Treinando ExtraTreesRegressor\n",
      "Train score 0.9758351645143398\n",
      "Validation score [0.72106654 0.75351199 0.67980316]\n",
      "Test score 0.7780531720809869\n",
      "================================================================================\n",
      "Treinando GammaRegressor\n",
      "Unable to coerce to Series, length must be 1: given 823\n",
      "Treinando GaussianProcessRegressor\n",
      "Train score 0.957307030988762\n",
      "Validation score [-50247.18582025 -29097.79403316 -55568.93145475]\n",
      "Test score -27442.34507505295\n",
      "================================================================================\n",
      "Treinando GradientBoostingRegressor\n",
      "Train score 0.8377769135634637\n",
      "Validation score [0.75178479 0.75460704 0.72487358]\n",
      "Test score 0.7802369699397751\n",
      "================================================================================\n",
      "Treinando HistGradientBoostingRegressor\n",
      "Train score 0.8709852363371758\n",
      "Validation score [0.73500322 0.75357837 0.7085305 ]\n",
      "Test score 0.7833022455656028\n",
      "================================================================================\n",
      "Treinando HuberRegressor\n",
      "Train score 0.7402145862564904\n",
      "Validation score [0.7275219  0.72494038 0.69140681]\n",
      "Test score 0.7519477489058045\n",
      "================================================================================\n",
      "Treinando IsotonicRegression\n",
      "Isotonic regression input X should be a 1d array or 2d array with 1 feature\n",
      "Treinando KNeighborsRegressor\n",
      "Train score 0.7985911413749257\n",
      "Validation score [0.67509233 0.72725421 0.66120571]\n",
      "Test score 0.7209396684217904\n",
      "================================================================================\n",
      "Treinando KernelRidge\n",
      "Train score 0.7144318719270017\n",
      "Validation score [0.66213246 0.67479862 0.64354497]\n",
      "Test score 0.754386057378067\n",
      "================================================================================\n",
      "Treinando Lars\n",
      "Train score 0.7413310011623597\n",
      "Validation score [0.73911744 0.73861513 0.69377154]\n",
      "Test score 0.7533225177776965\n",
      "================================================================================\n",
      "Treinando LarsCV\n",
      "Train score 0.7411524417180725\n",
      "Validation score [0.73374297 0.7499488  0.69538163]\n",
      "Test score 0.7522050127803528\n",
      "================================================================================\n",
      "Treinando Lasso\n",
      "Train score 0.32985890944130614\n",
      "Validation score [0.33820975 0.31518437 0.30769971]\n",
      "Test score 0.29007582637336415\n",
      "================================================================================\n",
      "Treinando LassoCV\n",
      "Train score 0.7411509146952949\n",
      "Validation score [0.73564154 0.7441469  0.69401543]\n",
      "Test score 0.7523962548838591\n",
      "================================================================================\n",
      "Treinando LassoLars\n",
      "Train score 0.0\n",
      "Validation score [-5.84323116e-05 -4.15321710e-03 -5.54408125e-03]\n",
      "Test score -0.001309354247712946\n",
      "================================================================================\n",
      "Treinando LassoLarsCV\n",
      "Train score 0.7411524417180725\n",
      "Validation score [0.73374297 0.7499488  0.69538163]\n",
      "Test score 0.7522050127803528\n",
      "================================================================================\n",
      "Treinando LassoLarsIC\n",
      "Train score 0.73820768261794\n",
      "Validation score [0.73060792 0.74992602 0.69685655]\n",
      "Test score 0.7466417237262364\n",
      "================================================================================\n",
      "Treinando LinearRegression\n",
      "Train score 0.7413310011623597\n",
      "Validation score [0.73911744 0.73861513 0.69377154]\n",
      "Test score 0.7533225177776965\n",
      "================================================================================\n",
      "Treinando LinearSVR\n",
      "Train score 0.7387668002410448\n",
      "Validation score [0.72538678 0.7230593  0.68773501]\n",
      "Test score 0.7552009507284514\n",
      "================================================================================\n",
      "Treinando MLPRegressor\n",
      "Train score 0.7642490256296919\n",
      "Validation score [0.6916681  0.66177518 0.61530038]\n",
      "Test score 0.7657477689570519\n",
      "================================================================================\n",
      "Treinando MultiTaskElasticNet\n",
      "Train score 0.5199369211585148\n",
      "Validation score [0.50630055 0.55223271 0.49009927]\n",
      "Test score 0.4775760850657844\n",
      "================================================================================\n",
      "Treinando MultiTaskElasticNetCV\n",
      "Train score 0.741066736968291\n",
      "Validation score [0.73581586 0.74379029 0.69400522]\n",
      "Test score 0.7522025736922537\n",
      "================================================================================\n",
      "Treinando MultiTaskLasso\n",
      "Train score 0.32985890944130614\n",
      "Validation score [0.33820975 0.31518437 0.30769971]\n",
      "Test score 0.29007582637336415\n",
      "================================================================================\n",
      "Treinando MultiTaskLassoCV\n",
      "Train score 0.7411509146952949\n",
      "Validation score [0.73564154 0.7441469  0.69401543]\n",
      "Test score 0.7523962548838591\n",
      "================================================================================\n",
      "Treinando NuSVR\n",
      "Train score 0.7741575365513402\n",
      "Validation score [0.75719903 0.73867901 0.72049201]\n",
      "Test score 0.7748277645410012\n",
      "================================================================================\n",
      "Treinando OrthogonalMatchingPursuit\n",
      "Train score 0.6537218802545044\n",
      "Validation score [0.60834304 0.663445   0.68147858]\n",
      "Test score 0.7205975680758073\n",
      "================================================================================\n",
      "Treinando OrthogonalMatchingPursuitCV\n",
      "Train score 0.7407124169255863\n",
      "Validation score [0.73879356 0.74939897 0.69852875]\n",
      "Test score 0.7505917431469655\n",
      "================================================================================\n",
      "Treinando PLSCanonical\n",
      "Train score -0.09416222498885407\n",
      "Validation score [ 0.18247247 -0.36201248 -0.15175697]\n",
      "Test score 0.18048696514510731\n",
      "================================================================================\n",
      "Treinando PLSRegression\n",
      "Train score 0.7274042012278579\n",
      "Validation score [0.73111665 0.74157053 0.68062847]\n",
      "Test score 0.7360345197704854\n",
      "================================================================================\n",
      "Treinando PassiveAggressiveRegressor\n",
      "Train score 0.5884147635013277\n",
      "Validation score [0.74688437 0.14708114 0.61368999]\n",
      "Test score 0.5840882674252779\n",
      "================================================================================\n",
      "Treinando PoissonRegressor\n",
      "Unable to coerce to Series, length must be 1: given 823\n",
      "Treinando RANSACRegressor\n",
      "Train score 0.6250170766965458\n",
      "Validation score [0.72540199 0.54115987 0.37904036]\n",
      "Test score 0.6429189370171342\n",
      "================================================================================\n",
      "Treinando RadiusNeighborsRegressor\n",
      "Input contains NaN, infinity or a value too large for dtype('float64').\n",
      "Treinando RandomForestRegressor\n",
      "Train score 0.9455569290516646\n",
      "Validation score [0.73321527 0.75549817 0.72873865]\n",
      "Test score 0.7854787011538364\n",
      "================================================================================\n",
      "Treinando Ridge\n",
      "Train score 0.7413273504004801\n",
      "Validation score [0.73918287 0.73885379 0.69387009]\n",
      "Test score 0.7531546911164785\n",
      "================================================================================\n",
      "Treinando RidgeCV\n",
      "Train score 0.7410195029403779\n",
      "Validation score [0.73897873 0.74035323 0.69405378]\n",
      "Test score 0.7514890113812608\n",
      "================================================================================\n",
      "Treinando SGDRegressor\n",
      "Train score 0.5803289776448832\n",
      "Validation score [0.53031667 0.14060116 0.5961021 ]\n",
      "Test score 0.6362939824575304\n",
      "================================================================================\n",
      "Treinando SVR\n",
      "Train score 0.7757415229091802\n",
      "Validation score [0.7554474  0.73365338 0.71894524]\n",
      "Test score 0.7693913413524824\n",
      "================================================================================\n",
      "Treinando TheilSenRegressor\n",
      "Train score 0.6720918921866665\n",
      "Validation score [0.72290033 0.64062661 0.61702234]\n",
      "Test score 0.6758704946346701\n",
      "================================================================================\n",
      "Treinando TransformedTargetRegressor\n",
      "Train score 0.7413310011623597\n",
      "Validation score [0.73911744 0.73861513 0.69377154]\n",
      "Test score 0.7533225177776965\n",
      "================================================================================\n",
      "Treinando TweedieRegressor\n",
      "Unable to coerce to Series, length must be 1: given 823\n"
     ]
    }
   ],
   "source": [
    "for reg in all_regs:\n",
    "  try:\n",
    "    print('Treinando', reg.__class__.__name__)\n",
    "    reg.fit(X_train, y_train)\n",
    "    train_score = reg.score(X_train, y_train)\n",
    "    val_score = cross_val_score(reg, X_train, y_train, cv=3)\n",
    "    test_score = reg.score(X_test, y_test)\n",
    "    print('Train score', train_score)\n",
    "    print('Validation score', val_score)\n",
    "    print('Test score', test_score)\n",
    "    print('='*80)\n",
    "  except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "irish-franchise",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
