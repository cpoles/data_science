{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "narrative-range",
   "metadata": {},
   "source": [
    "# Data Analysis of the Book Pride and Prejudice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continental-pierre",
   "metadata": {},
   "source": [
    "## Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "lesbian-think",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14061\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with open('pride_prejudice.txt') as ppbook:\n",
    "        lines = ppbook.readlines()\n",
    "        print(len(lines))\n",
    "except FileNotFoundError:\n",
    "    print('File not found.')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "spanish-finland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['      Chapter 1\\n',\n",
       " '\\n',\n",
       " '      It is a truth universally acknowledged, that a single man in\\n',\n",
       " '      possession of a good fortune, must be in want of a wife.\\n',\n",
       " '\\n',\n",
       " '      However little known the feelings or views of such a man may be\\n',\n",
       " '      on his first entering a neighbourhood, this truth is so well\\n',\n",
       " '      fixed in the minds of the surrounding families, that he is\\n',\n",
       " '      considered the rightful property of some one or other of their\\n',\n",
       " '      daughters.\\n',\n",
       " '\\n',\n",
       " '      “My dear Mr. Bennet,” said his lady to him one day, “have you\\n',\n",
       " '      heard that Netherfield Park is let at last?”\\n',\n",
       " '\\n',\n",
       " '      Mr. Bennet replied that he had not.\\n']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[0:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applicable-royal",
   "metadata": {},
   "source": [
    "## Data Munging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "stuffed-institution",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove punctuation and special characters\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neural-melissa",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adjacent-diana",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_line(line: str) -> str:\n",
    "    # remove trailing and leading spaces\n",
    "    # remove punctuation\n",
    "    line = re.sub(r'[\\n,;`:.\"“”‘’„”«»><{}\\[\\]|+=_()*&%$#@!~\\'?]', '', line.strip())\n",
    "    return line.replace('—', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "japanese-melissa",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_lines = list(map(clean_line, lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "hollywood-despite",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Chapter 1',\n",
       " '',\n",
       " 'It is a truth universally acknowledged that a single man in',\n",
       " 'possession of a good fortune must be in want of a wife',\n",
       " '',\n",
       " 'However little known the feelings or views of such a man may be',\n",
       " 'on his first entering a neighbourhood this truth is so well',\n",
       " 'fixed in the minds of the surrounding families that he is',\n",
       " 'considered the rightful property of some one or other of their',\n",
       " 'daughters',\n",
       " '',\n",
       " 'My dear Mr Bennet said his lady to him one day have you',\n",
       " 'heard that Netherfield Park is let at last',\n",
       " '',\n",
       " 'Mr Bennet replied that he had not']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_lines[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "constitutional-complaint",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove empty lines\n",
    "clean_lines0 = [line for line in clean_lines if not line == '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "confused-rates",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "540 µs ± 1.05 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "# time using list comprehension\n",
    "%timeit [line for line in clean_lines if not line == '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "meaningful-career",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_lines1 = list(filter(lambda x: x != '', clean_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "severe-princeton",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.05 ms ± 1.16 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "# time using filter\n",
    "%timeit list(filter(lambda x: x != '', clean_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "featured-andorra",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_lines2 = [line for line in clean_lines if not re.fullmatch(r'^\\s*$', line)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "composed-shuttle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.18 ms ± 41.4 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "# time using regex and list comprehension\n",
    "%timeit [line for line in clean_lines if not re.fullmatch(r'^\\s*$', line)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "shared-madrid",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Chapter 1',\n",
       " 'It is a truth universally acknowledged that a single man in',\n",
       " 'possession of a good fortune must be in want of a wife',\n",
       " 'However little known the feelings or views of such a man may be',\n",
       " 'on his first entering a neighbourhood this truth is so well',\n",
       " 'fixed in the minds of the surrounding families that he is',\n",
       " 'considered the rightful property of some one or other of their',\n",
       " 'daughters',\n",
       " 'My dear Mr Bennet said his lady to him one day have you',\n",
       " 'heard that Netherfield Park is let at last']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_lines0[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "further-trustee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Chapter 1',\n",
       " 'It is a truth universally acknowledged that a single man in',\n",
       " 'possession of a good fortune must be in want of a wife',\n",
       " 'However little known the feelings or views of such a man may be',\n",
       " 'on his first entering a neighbourhood this truth is so well',\n",
       " 'fixed in the minds of the surrounding families that he is',\n",
       " 'considered the rightful property of some one or other of their',\n",
       " 'daughters',\n",
       " 'My dear Mr Bennet said his lady to him one day have you',\n",
       " 'heard that Netherfield Park is let at last']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_lines1[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "convinced-sheffield",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Chapter 1',\n",
       " 'It is a truth universally acknowledged that a single man in',\n",
       " 'possession of a good fortune must be in want of a wife',\n",
       " 'However little known the feelings or views of such a man may be',\n",
       " 'on his first entering a neighbourhood this truth is so well',\n",
       " 'fixed in the minds of the surrounding families that he is',\n",
       " 'considered the rightful property of some one or other of their',\n",
       " 'daughters',\n",
       " 'My dear Mr Bennet said his lady to him one day have you',\n",
       " 'heard that Netherfield Park is let at last']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_lines2[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fiscal-providence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_lines0 == clean_lines2 and clean_lines1 == clean_lines0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moved-invention",
   "metadata": {},
   "source": [
    "### Data Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "original-dubai",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize each sentence into words\n",
    "words_list = list(map(lambda x: x.split(), clean_lines0))\n",
    "# make every word the same case (upper or lower)\n",
    "def list_to_lower(seq: list): return list(map(lambda x: x.lower(), seq))\n",
    "words_list = list(map(list_to_lower , words_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "spoken-grain",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flattening the words_list\n",
    "# concatenate all lists of words\n",
    "wlist_flat = [word for words in words_list for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "portable-alias",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chapter',\n",
       " '1',\n",
       " 'it',\n",
       " 'is',\n",
       " 'a',\n",
       " 'truth',\n",
       " 'universally',\n",
       " 'acknowledged',\n",
       " 'that',\n",
       " 'a',\n",
       " 'single',\n",
       " 'man',\n",
       " 'in',\n",
       " 'possession',\n",
       " 'of']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wlist_flat[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "brutal-bangkok",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.78 ms ± 15.8 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "# time flattening method 1\n",
    "%timeit [word for words in words_list for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "proved-course",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time flattening method 2\n",
    "flattened_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "after-theme",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.26 ms ± 13.6 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "for x in words_list:\n",
    "    for y in x:\n",
    "        flattened_list.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "complimentary-treaty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chapter',\n",
       " '1',\n",
       " 'it',\n",
       " 'is',\n",
       " 'a',\n",
       " 'truth',\n",
       " 'universally',\n",
       " 'acknowledged',\n",
       " 'that',\n",
       " 'a',\n",
       " 'single',\n",
       " 'man',\n",
       " 'in',\n",
       " 'possession',\n",
       " 'of']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flattened_list[0:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustainable-darwin",
   "metadata": {},
   "source": [
    "## Data Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respective-tract",
   "metadata": {},
   "source": [
    "#### Word Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ruled-legend",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a set to get unique words\n",
    "uniq_w = set(wlist_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "upset-federal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary with unique word: [occurence]\n",
    "dic_occ = dict.fromkeys(uniq_w, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "postal-strengthening",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.1 ms ± 86.7 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# count occurrence of words\n",
    "for word in wlist_flat:\n",
    "    if word in dic_occ:\n",
    "        dic_occ[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "naughty-endorsement",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "standard-battlefield",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_occ1 = Counter(wlist_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "chief-mirror",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.58 ms ± 32 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit Counter(wlist_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "direct-manual",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "#### Average Sencence Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "unable-consultancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get average sentence length\n",
    "# map list to a list of its sublists lengths\n",
    "# sum the mapped list\n",
    "sentence_len = sum(list(map(lambda x: len(x), clean_lines0)))\n",
    "avg_sent_len = sentence_len // len(clean_lines0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "valid-mortgage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Sentence Length: 54 characters\n"
     ]
    }
   ],
   "source": [
    "print(f'Average Sentence Length: {avg_sent_len} characters')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occasional-toilet",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "#### Total Character Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "saving-typing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of characters is: 536,835\n"
     ]
    }
   ],
   "source": [
    "total_chars = sum(map(lambda x: len(x), wlist_flat))\n",
    "print(f'The total number of characters is: {total_chars:,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cathedral-homework",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "#### Total Word Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "finite-willow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of words is: 121,870\n"
     ]
    }
   ],
   "source": [
    "print(f'The total number of words is: {len(wlist_flat):,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cardiovascular-patch",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "#### Total Unique Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "failing-habitat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of unique words is: 6,488\n"
     ]
    }
   ],
   "source": [
    "print(f'The total number of unique words is: {len(uniq_w):,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prompt-thickness",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "#### Top 10 Longest Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "reverse-deadline",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_l = sorted(list(uniq_w), key=len, reverse=True)\n",
    "# remove hyphenated words\n",
    "sorted_hyphens = list(filter(lambda x: re.match(r'^(.*)-(.*)$', x), sorted_l))\n",
    "\n",
    "sorted_no_hyphens = list(filter(lambda x: not re.match(r'^(.*)-(.*)', x), sorted_l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "perfect-religious",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Top 10 Longest Words  \n",
      "\n",
      "Word                Size\n",
      "\n",
      "communicativeness     17\n",
      "disinterestedness     17\n",
      "misrepresentation     17\n",
      "superciliousness      16\n",
      "discontentedness      16\n",
      "incomprehensible      16\n",
      "superintendence       15\n",
      "acknowledgments       15\n",
      "thoughtlessness       15\n",
      "inconsistencies       15\n"
     ]
    }
   ],
   "source": [
    "print(f\"{'Top 10 Longest Words':^24}\\n\")\n",
    "print(f\"{'Word':<20}{'Size':>4}\\n\")\n",
    "\n",
    "for word in sorted_no_hyphens[0:10]:\n",
    "    print(f'{word:<20}{len(word):>4}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pacific-twelve",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
