{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d572b360",
   "metadata": {},
   "source": [
    "# PROJECT : Mammogram Classification Using CNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8201a970",
   "metadata": {},
   "source": [
    "DATASET: THE MIAS-MAMMOGRAPHY DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e629e4f9",
   "metadata": {},
   "source": [
    "INFORMATION:\n",
    "\n",
    "This file lists the films in the MIAS database and provides     \n",
    "appropriate details as follows:\n",
    "\n",
    "1st column: MIAS database reference number.\n",
    "\n",
    "2nd column: Character of background tissue: \n",
    "                F - Fatty \n",
    "                G - Fatty-glandular\n",
    "                D - Dense-glandular\n",
    "\n",
    "3rd column: Class of abnormality present:\n",
    "                CALC - Calcification\n",
    "                CIRC - Well-defined/circumscribed masses\n",
    "                SPIC - Spiculated masses\n",
    "                MISC - Other, ill-defined masses\n",
    "                ARCH - Architectural distortion\n",
    "                ASYM - Asymmetry\n",
    "                NORM - Normal\n",
    "\n",
    "4th column: Severity of abnormality;\n",
    "                B - Benign\n",
    "                M - Malignant\n",
    "                \n",
    "5th,6th columns: x,y image-coordinates of centre of abnormality.\n",
    "\n",
    "7th column: Approximate radius (in pixels) of a circle enclosing\n",
    "            the abnormality.\n",
    "            \n",
    "NOTES\n",
    "\n",
    "1- The list is arranged in pairs of films, where each pair \n",
    "   represents the left (even filename numbers) and right mammograms\n",
    "   (odd filename numbers) of a single patient.\n",
    "   \n",
    "2- The size of ALL the images is 1024 pixels x 1024 pixels. The images\n",
    "   have been centered in the matrix.  \n",
    "\n",
    "3- When calcifications are present, centre locations and radii \n",
    "   apply to clusters rather than individual calcifications.\n",
    "   Coordinate system origin is the bottom-left corner.\n",
    "\n",
    "4- In some cases calcifications are widely distributed throughout\n",
    "   the image rather than concentrated at a single site. In these\n",
    "   cases centre locations and radii are inappropriate and have\n",
    "   been omitted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bc03a2",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c0b858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# system related\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../src/')\n",
    "# import custom modules\n",
    "from modules import helpers as hp\n",
    "from modules import mammoscan as ms\n",
    "\n",
    "# path manipulation\n",
    "from pathlib import Path\n",
    "\n",
    "# regex\n",
    "import re\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib.patches import Circle\n",
    "\n",
    "# data manipulation / preparation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# image manipulation\n",
    "from PIL import Image\n",
    "from IPython.display import Image\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "# keras\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten, MaxPool2D, Dropout, Input\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109d0409",
   "metadata": {},
   "source": [
    "### Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56accd93",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "#### Get the scans data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a75d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mias = hp.create_mias_dataset('../scan_file_data.txt')\n",
    "mias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba2ebcf",
   "metadata": {
    "heading_collapsed": "true"
   },
   "source": [
    "### Data Preparation / Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fbcfa2",
   "metadata": {},
   "source": [
    "This process takes the original images (1024x1024) and generates rotated and mirrored subsamples of them. \n",
    "\n",
    "The subsamples generated by this process have size (48x48) and rotated versions by 0, 90, 180, 270 degrees.\n",
    "\n",
    "There also are top/bottom and right/left mirrored versions of the original images.\n",
    "\n",
    "Originally, the clean dataset has 319 images. \n",
    "\n",
    "The transformation process produces 3828 images. \n",
    "\n",
    "That is to say that for each image, 12 new images are created or a 1200% increase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60ee2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "mias = hp.generate_subsamples('../all-mias/', mias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdb74a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7123f73",
   "metadata": {},
   "source": [
    "#### Data Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5833536a",
   "metadata": {},
   "source": [
    "The NORM class, which accounts for the scans with no abnormalities, stands for 64.8% of the scan samples. Its severity was defined as 'A' and it happens during the creation of the mias dataframe.\n",
    "\n",
    "There is also a slight difference between Malign (M) and Benign (B) samples in all classes\n",
    "\n",
    "The strategy to atenuate such disparity is to randomly remove whichever class is predominant (either M or N) so that we can have a balanced set. Classes to be balanced prior to be tested to ensure randomness.\n",
    "\n",
    "As for the NORM class, it will reduced, also randomly, to the average of the samples for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e0fff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mias.groupby(['ab_class']).severity.value_counts() / len(mias.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c48405",
   "metadata": {},
   "outputs": [],
   "source": [
    "mias.groupby(['ab_class', 'severity']).size().unstack().plot(kind='bar', \n",
    "                                                               figsize=(10, 8), \n",
    "                                                               xlabel='Abnormality Class', \n",
    "                                                               ylabel='SCANS',\n",
    "                                                               title='SEVERITY BY CLASS');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2d9ce5",
   "metadata": {},
   "source": [
    "Abnormalities only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f54a70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mias[mias.ab_class != 'NORM'].groupby(['ab_class', 'severity']).size().unstack().plot(kind='bar', \n",
    "                                                                                      stacked=True, \n",
    "                                                                                      figsize=(10, 8), \n",
    "                                                                                      xlabel='ABNORMALITIES ONLY', \n",
    "                                                                                      ylabel='Percentage',\n",
    "                                                                                      title='SEVERITY BY CLASS');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cf38e6",
   "metadata": {},
   "source": [
    "#### Dataset balancing Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0618c699",
   "metadata": {},
   "source": [
    "Calcifications before balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10973ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "calcifications_unbalanced = mias[mias.ab_class == 'CALC']\n",
    "\n",
    "calcifications_unbalanced.severity.value_counts().plot(kind='bar');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d60b6e",
   "metadata": {},
   "source": [
    "Calcifications after balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ada387",
   "metadata": {},
   "outputs": [],
   "source": [
    "calcifications_balanced = hp.balance_by_severity(mias, 'CALC')\n",
    "\n",
    "calcifications_balanced.severity.value_counts().plot(kind='bar');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75607173",
   "metadata": {},
   "source": [
    "#### Final Results Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847ea16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results = hp.create_final_results_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65b3406",
   "metadata": {},
   "source": [
    "### TRAIN AND EVALUATE MODEL FOR CALCIFICATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991be47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "calcifications = hp.balance_by_severity(mias, 'CALC')\n",
    "calcifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f10acdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "calcifications = calcifications.sample(len(calcifications), replace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4137989e",
   "metadata": {},
   "source": [
    "#### Generate Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb1c194",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator = ImageDataGenerator(validation_split=.25, \n",
    "                                    height_shift_range=.10, \n",
    "                                    width_shift_range=.10, \n",
    "                                    rotation_range=30, \n",
    "                                    rescale=1/255.)\n",
    "\n",
    "# train data\n",
    "train_data = data_generator.flow_from_dataframe(calcifications, \n",
    "                                                x_col=\"subsample_path\", \n",
    "                                                y_col=\"severity\",\n",
    "                                                class_mode=\"categorical\",\n",
    "                                                target_size=(48,48),\n",
    "                                                subset=\"training\",\n",
    "                                                color_mode=\"grayscale\",\n",
    "                                                shuffle=True)\n",
    "\n",
    "# test data\n",
    "test_data = data_generator.flow_from_dataframe(calcifications, \n",
    "                                               x_col=\"subsample_path\", \n",
    "                                               y_col=\"severity\",\n",
    "                                               class_mode=\"categorical\",\n",
    "                                               target_size=(48,48),\n",
    "                                               subset=\"validation\",\n",
    "                                               color_mode=\"grayscale\",\n",
    "                                               shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e2d2b5",
   "metadata": {},
   "source": [
    "#### Create Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7d101b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_calc = Sequential()\n",
    "# first layer\n",
    "cnn_calc.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=(48, 48, 1)))\n",
    "cnn_calc.add(Conv2D(64, kernel_size=(3,3),activation='relu'))\n",
    "cnn_calc.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "cnn_calc.add(Conv2D(64, kernel_size=(3,3),activation='relu'))\n",
    "cnn_calc.add(MaxPool2D(pool_size=(2, 2)))\n",
    "cnn_calc.add(Dropout(0.25))\n",
    "# Add dense layer to reduce the number of features\n",
    "cnn_calc.add(Dense(64, activation='relu'))\n",
    "cnn_calc.add(Dropout(0.25))\n",
    "# flattening results\n",
    "cnn_calc.add(Flatten())\n",
    "# Dense layer to produce final output\n",
    "cnn_calc.add(Dense(2, activation='softmax'))\n",
    "# print summary\n",
    "cnn_calc.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0efd54",
   "metadata": {},
   "source": [
    "#### Visualise the Model's Structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2cf8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(cnn_calc, to_file='convnet.png', show_shapes=True, show_layer_names=True)\n",
    "Image(filename='convnet.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa28447",
   "metadata": {},
   "source": [
    "#### Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3381775e",
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = Adam(0.001)\n",
    "cnn_calc.compile(optimizer=adam,\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0df7a87",
   "metadata": {},
   "source": [
    "#### Training and Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd78382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set callbacks\n",
    "early_stopping = EarlyStopping(patience=10_000, restore_best_weights=True)\n",
    "\n",
    "\n",
    "model_check_point = ModelCheckpoint(filepath= './', \n",
    "                                    monitor='val_loss', verbose=1, \n",
    "                                    save_best_only=True,\n",
    "                                    save_weights_only=False, \n",
    "                                    mode='auto', save_freq='epoch')\n",
    "\n",
    "# fit the model\n",
    "hist = cnn_calc.fit(train_data, \n",
    "                    validation_data=test_data, \n",
    "                    epochs=10_000,\n",
    "                    callbacks=[early_stopping, model_check_point])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff31571c",
   "metadata": {},
   "source": [
    "#### Making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f7e57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions\n",
    "predictions = cnn_calc.predict(test_data)\n",
    "predicted = [np.argmax(w) for w in predictions]\n",
    "expected = test_data.labels\n",
    "\n",
    "\n",
    "# Evaluation Results\n",
    "loss_value , accuracy = cnn_calc.evaluate(train_data)\n",
    "\n",
    "print(f'Test loss_value: {loss_value}')\n",
    "print(f'Test accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b475fa",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c05b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(expected, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5866e18",
   "metadata": {},
   "source": [
    "#### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699eac59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B, M or A\n",
    "print(f'Classes: {test_data.class_indices}\\n')\n",
    "print(classification_report(expected, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795b5d5a",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36fa101",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_plot = hp.plot_results(hist.history['accuracy'],\n",
    "                            hist.history['val_accuracy'], \n",
    "                            hist.history['loss'], \n",
    "                            hist.history['val_loss'])\n",
    "\n",
    "# enter data to the final results dataframe\n",
    "results_calc = classification_report(expected, predicted, output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8826f466",
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_malignant = results_calc['1']\n",
    "calc_malignant\n",
    "final_results.loc['calcifications'] = (accuracy,\n",
    "                                       calc_malignant['precision'], \n",
    "                                       calc_malignant['recall'], \n",
    "                                       calc_malignant['f1-score'])\n",
    "final_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4fd156",
   "metadata": {},
   "source": [
    "#### Checking Wrong Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e459e5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking wrong predictions\n",
    "wrong_predictions = []\n",
    "images = calcifications.p_matrix\n",
    "predictions = cnn_calc.predict(test_data)\n",
    "\n",
    "for i, (p,e) in enumerate(zip(predictions, test_data.labels)):\n",
    "    predicted, expected = np.argmax(p), np.argmax(e)\n",
    "\n",
    "    if predicted != expected:\n",
    "        wrong_predictions.append(\n",
    "            (i, images[i], predicted, expected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75dddb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(wrong_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed81cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c,d = wrong_predictions[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3f07ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.display_probabilities(predictions[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb56c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = calcifications.iloc[a].loc['p_matrix'] == b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a51fba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ece2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, axes = plt.subplots(nrows=5, ncols=6, figsize=(16, 12))\n",
    "\n",
    "for axes, item in zip(axes.ravel(), wrong_predictions):\n",
    "    index, image, predicted, expected = item\n",
    "    axes.imshow(image, cmap=plt.cm.gray_r)\n",
    "    axes.set_title(\n",
    "                    f'image: {calcifications.iloc[index].name}\\np: {predicted}; e: {expected}'                   \n",
    "                   )\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97c6a1c",
   "metadata": {},
   "source": [
    "### TRAIN AND EVALUATE MODEL FOR MASSES (FULL BALANCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4629483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare dataset\n",
    "circ_balanced = hp.balance_by_severity(mias, 'CIRC')\n",
    "spic_balanced = hp.balance_by_severity(mias, 'SPIC')\n",
    "misc_balanced = hp.balance_by_severity(mias, 'MISC')\n",
    "# shuffle using the length of the smallest sample (CIRC)\n",
    "circ_balanced = circ_balanced.sample(len(circ_balanced), replace=False)\n",
    "spic_balanced = spic_balanced.sample(len(circ_balanced), replace=False)\n",
    "misc_balanced = misc_balanced.sample(len(circ_balanced), replace=False)\n",
    "# create new dataframe for the masses only\n",
    "masses_balanced = pd.concat([circ_balanced, spic_balanced])\n",
    "masses_balanced = pd.concat([masses_balanced, misc_balanced])\n",
    "# masses dataset\n",
    "masses_balanced = masses_balanced.sample(len(masses_balanced), replace=False)\n",
    "masses_balanced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905717da",
   "metadata": {},
   "source": [
    "#### Check Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9ec53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "masses_balanced.groupby('ab_class').severity.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49be2a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "masses_balanced.groupby(['ab_class', 'severity']).severity.size().unstack().plot(kind='bar', \n",
    "                                                                      stacked=True, \n",
    "                                                                      figsize=(10, 8), \n",
    "                                                                      xlabel='Abnormality Class', \n",
    "                                                                      ylabel='Percentage',\n",
    "                                                                      title='SEVERITY BY CLASS');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a59fd3",
   "metadata": {},
   "source": [
    "#### Generate Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4e3d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator = ImageDataGenerator(validation_split=.25, \n",
    "                                    height_shift_range=.10, \n",
    "                                    width_shift_range=.10, \n",
    "                                    rotation_range=30, \n",
    "                                    rescale=1/255.)\n",
    "\n",
    "train_data = data_generator.flow_from_dataframe(masses_balanced, \n",
    "                                                x_col=\"subsample_path\", \n",
    "                                                y_col=\"severity\",\n",
    "                                                class_mode=\"categorical\",\n",
    "                                                target_size=(48,48),\n",
    "                                                subset=\"training\",\n",
    "                                                color_mode=\"grayscale\",\n",
    "                                                shuffle=True)\n",
    "test_data = data_generator.flow_from_dataframe(masses_balanced, \n",
    "                                               x_col=\"subsample_path\", \n",
    "                                               y_col=\"severity\",\n",
    "                                               class_mode=\"categorical\",\n",
    "                                               target_size=(48,48),\n",
    "                                               subset=\"validation\",\n",
    "                                               color_mode=\"grayscale\",\n",
    "                                               shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344c825e",
   "metadata": {},
   "source": [
    "#### Create Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5635d8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "mass_cnn = Sequential()\n",
    "# first layer\n",
    "mass_cnn.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=(48, 48, 1)))\n",
    "mass_cnn.add(Conv2D(64, kernel_size=(3,3),activation='relu'))\n",
    "mass_cnn.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "mass_cnn.add(Conv2D(64, kernel_size=(3,3),activation='relu'))\n",
    "mass_cnn.add(MaxPool2D(pool_size=(2, 2)))\n",
    "mass_cnn.add(Dropout(0.25))\n",
    "# Add dense layer to reduce the number of features\n",
    "mass_cnn.add(Dense(64, activation='relu'))\n",
    "mass_cnn.add(Dropout(0.25))\n",
    "# flattening results\n",
    "mass_cnn.add(Flatten())\n",
    "# Dense layer to produce final output\n",
    "mass_cnn.add(Dense(2, activation='softmax'))\n",
    "# print summary\n",
    "mass_cnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccf0e28",
   "metadata": {},
   "source": [
    "#### Visualise the Model's Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d19ae8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(mass_cnn, to_file='convnet.png', show_shapes=True, show_layer_names=True)\n",
    "Image(filename='convnet.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c61c318",
   "metadata": {},
   "source": [
    "#### Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9967b77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # set optmizer and learning rate\n",
    "adam = Adam(0.001)\n",
    "mass_cnn.compile(optimizer=adam,\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6407d110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set callbacks\n",
    "early_stopping = EarlyStopping(patience=10_000, restore_best_weights=True)\n",
    "\n",
    "\n",
    "model_check_point = ModelCheckpoint(filepath= './', \n",
    "                                    monitor='val_loss', verbose=1, \n",
    "                                    save_best_only=True,\n",
    "                                    save_weights_only=False, \n",
    "                                    mode='auto', save_freq='epoch')\n",
    "\n",
    "# fit the model\n",
    "hist = mass_cnn.fit(train_data, \n",
    "                    validation_data=test_data, \n",
    "                    epochs=10_000,\n",
    "                    callbacks=[early_stopping, model_check_point])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a115ac2",
   "metadata": {},
   "source": [
    "#### Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64589c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions\n",
    "predictions = mass_cnn.predict(test_data)\n",
    "predicted = [np.argmax(w) for w in predictions]\n",
    "expected = test_data.labels\n",
    "\n",
    "\n",
    "# Evaluation Results\n",
    "loss_value , accuracy = mass_cnn.evaluate(train_data)\n",
    "\n",
    "print(f'Test loss_value: {loss_value}')\n",
    "print(f'Test accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60326fcf",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425f4bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(expected, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0b2fc3",
   "metadata": {},
   "source": [
    "#### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fa1925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B, M or A\n",
    "print(f'Classes: {test_data.class_indices}\\n')\n",
    "print(classification_report(expected, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89dd0ea0",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f52b08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_plot = hp.plot_results(hist.history['accuracy'],\n",
    "                               hist.history['val_accuracy'], \n",
    "                               hist.history['loss'], \n",
    "                               hist.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b096e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter data to the final results dataframe\n",
    "results_mass = classification_report(expected, predicted, output_dict=True)\n",
    "# add entry to the final_results\n",
    "mass_malignant = results_mass['1']\n",
    "mass_malignant\n",
    "final_results.loc['masses_full_bal'] = (accuracy, \n",
    "                                       mass_malignant['precision'], \n",
    "                                       mass_malignant['recall'], \n",
    "                                       mass_malignant['f1-score'])\n",
    "final_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297b7e79",
   "metadata": {},
   "source": [
    "#### Checking Wrong Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71261753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking wrong predictions\n",
    "predictions = mass_cnn.predict(test_data)\n",
    "\n",
    "# check the probabilities for the first sample\n",
    "for index, probability in enumerate(predictions[0]):\n",
    "    print(f'{index}: {probability:.10%}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76275e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = masses_balanced.p_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7142cc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_predictions = []\n",
    "\n",
    "for i, (p,e) in enumerate(zip(predictions, test_data.labels)):\n",
    "    predicted, expected = np.argmax(p), np.argmax(e)\n",
    "    if predicted != expected:\n",
    "        wrong_predictions.append(\n",
    "            (i, images[i], predicted, expected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3b0a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(wrong_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5922d0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c,d = wrong_predictions[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96a5d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.display_probabilities(predictions[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f68aa53",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = masses_balanced.iloc[a].loc['p_matrix'] == b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1897fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21aae5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, axes = plt.subplots(nrows=3, ncols=6, figsize=(16, 12))\n",
    "\n",
    "for axes, item in zip(axes.ravel(), wrong_predictions):\n",
    "    index, image, predicted, expected = item\n",
    "    axes.imshow(image, cmap=plt.cm.gray_r)\n",
    "    axes.set_title(\n",
    "                    f'image: {masses_balanced.iloc[index].name}\\np: {predicted}; e: {expected}'                   \n",
    "                   )\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc47b75a",
   "metadata": {},
   "source": [
    "### TRAIN AND EVALUATE MODEL FOR MASSES (CLASS BALANCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fb57ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare dataset\n",
    "circ_balanced = hp.balance_by_severity(mias, 'CIRC')\n",
    "spic_balanced = hp.balance_by_severity(mias, 'SPIC')\n",
    "misc_balanced = hp.balance_by_severity(mias, 'MISC')\n",
    "# shuffle using the length of the smallest sample (CIRC)\n",
    "circ_balanced = circ_balanced.sample(len(circ_balanced), replace=False)\n",
    "spic_balanced = spic_balanced.sample(len(spic_balanced), replace=False)\n",
    "misc_balanced = misc_balanced.sample(len(misc_balanced), replace=False)\n",
    "# create new dataframe for the masses only\n",
    "masses_balanced = pd.concat([circ_balanced, spic_balanced])\n",
    "masses_balanced = pd.concat([masses_balanced, misc_balanced])\n",
    "# masses dataset\n",
    "masses_balanced = masses_balanced.sample(len(masses_balanced), replace=False)\n",
    "masses_balanced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4df6dcb",
   "metadata": {},
   "source": [
    "#### Check Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d0dcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "masses_balanced.groupby('ab_class').severity.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5b58e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "masses_balanced.groupby(['ab_class', 'severity']).severity.size().unstack().plot(kind='bar', \n",
    "                                                                      stacked=True, \n",
    "                                                                      figsize=(10, 8), \n",
    "                                                                      xlabel='Abnormality Class', \n",
    "                                                                      ylabel='Percentage',\n",
    "                                                                      title='SEVERITY BY CLASS');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5270073",
   "metadata": {},
   "source": [
    "#### Generate Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc424d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator = ImageDataGenerator(validation_split=.25, \n",
    "                                    height_shift_range=.10, \n",
    "                                    width_shift_range=.10, \n",
    "                                    rotation_range=30, \n",
    "                                    rescale=1/255.)\n",
    "\n",
    "train_data = data_generator.flow_from_dataframe(masses_balanced, \n",
    "                                                x_col=\"subsample_path\", \n",
    "                                                y_col=\"severity\",\n",
    "                                                class_mode=\"categorical\",\n",
    "                                                target_size=(48,48),\n",
    "                                                subset=\"training\",\n",
    "                                                color_mode=\"grayscale\",\n",
    "                                                shuffle=True)\n",
    "test_data = data_generator.flow_from_dataframe(masses_balanced, \n",
    "                                               x_col=\"subsample_path\", \n",
    "                                               y_col=\"severity\",\n",
    "                                               class_mode=\"categorical\",\n",
    "                                               target_size=(48,48),\n",
    "                                               subset=\"validation\",\n",
    "                                               color_mode=\"grayscale\",\n",
    "                                               shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606c0c1a",
   "metadata": {},
   "source": [
    "#### Create Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b965231e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mass_cnn = Sequential()\n",
    "# first layer\n",
    "mass_cnn.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=(48, 48, 1)))\n",
    "mass_cnn.add(Conv2D(64, kernel_size=(3,3),activation='relu'))\n",
    "mass_cnn.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "mass_cnn.add(Conv2D(64, kernel_size=(3,3),activation='relu'))\n",
    "mass_cnn.add(MaxPool2D(pool_size=(2, 2)))\n",
    "mass_cnn.add(Dropout(0.25))\n",
    "# Add dense layer to reduce the number of features\n",
    "mass_cnn.add(Dense(64, activation='relu'))\n",
    "mass_cnn.add(Dropout(0.25))\n",
    "# flattening results\n",
    "mass_cnn.add(Flatten())\n",
    "# Dense layer to produce final output\n",
    "mass_cnn.add(Dense(2, activation='softmax'))\n",
    "# print summary\n",
    "mass_cnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77897d8c",
   "metadata": {},
   "source": [
    "#### Visualise the Model's Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ebb55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(mass_cnn, to_file='convnet.png', show_shapes=True, show_layer_names=True)\n",
    "Image(filename='convnet.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e4fd35",
   "metadata": {},
   "source": [
    "#### Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c35638a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # set optmizer and learning rate\n",
    "adam = Adam(0.001)\n",
    "mass_cnn.compile(optimizer=adam,\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e602ce8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set callbacks\n",
    "early_stopping = EarlyStopping(patience=10_000, restore_best_weights=True)\n",
    "\n",
    "\n",
    "model_check_point = ModelCheckpoint(filepath= './', \n",
    "                                    monitor='val_loss', verbose=1, \n",
    "                                    save_best_only=True,\n",
    "                                    save_weights_only=False, \n",
    "                                    mode='auto', save_freq='epoch')\n",
    "\n",
    "# fit the model\n",
    "hist = mass_cnn.fit(train_data, \n",
    "                    validation_data=test_data, \n",
    "                    epochs=10_000,\n",
    "                    callbacks=[early_stopping, model_check_point])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f78373",
   "metadata": {},
   "source": [
    "#### Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af36b8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions\n",
    "predictions = mass_cnn.predict(test_data)\n",
    "predicted = [np.argmax(w) for w in predictions]\n",
    "expected = test_data.labels\n",
    "\n",
    "\n",
    "# Evaluation Results\n",
    "loss_value , accuracy = mass_cnn.evaluate(train_data)\n",
    "\n",
    "print(f'Test loss_value: {loss_value}')\n",
    "print(f'Test accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90da3ccc",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d16d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(expected, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58dd0f9",
   "metadata": {},
   "source": [
    "#### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0873fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B, M or A\n",
    "print(f'Classes: {test_data.class_indices}\\n')\n",
    "print(classification_report(expected, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e200633",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6da9627",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_plot = hp.plot_results(hist.history['accuracy'],\n",
    "                               hist.history['val_accuracy'], \n",
    "                               hist.history['loss'], \n",
    "                               hist.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcbcdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter data to the final results dataframe\n",
    "results_mass = classification_report(expected, predicted, output_dict=True)\n",
    "# add entry to the final_results\n",
    "mass_malignant = results_mass['1']\n",
    "mass_malignant\n",
    "final_results.loc['masses_bal'] = (accuracy,\n",
    "                                   mass_malignant['precision'], \n",
    "                                   mass_malignant['recall'], \n",
    "                                   mass_malignant['f1-score'])\n",
    "final_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f42f36",
   "metadata": {},
   "source": [
    "#### Checking Wrong Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed02e333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking wrong predictions\n",
    "predictions = mass_cnn.predict(test_data)\n",
    "\n",
    "# check the probabilities for the first sample\n",
    "for index, probability in enumerate(predictions[0]):\n",
    "    print(f'{index}: {probability:.10%}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f51ed3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = masses_balanced.p_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015ad1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_predictions = []\n",
    "\n",
    "for i, (p,e) in enumerate(zip(predictions, test_data.labels)):\n",
    "    predicted, expected = np.argmax(p), np.argmax(e)\n",
    "    if predicted != expected:\n",
    "        wrong_predictions.append(\n",
    "            (i, images[i], predicted, expected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6ab16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(wrong_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c3b436",
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c,d = wrong_predictions[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d95d819",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.display_probabilities(predictions[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a97b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = masses_balanced.iloc[a].loc['p_matrix'] == b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea8afc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9787902",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, axes = plt.subplots(nrows=3, ncols=6, figsize=(16, 12))\n",
    "\n",
    "for axes, item in zip(axes.ravel(), wrong_predictions):\n",
    "    index, image, predicted, expected = item\n",
    "    axes.imshow(image, cmap=plt.cm.gray_r)\n",
    "    axes.set_title(\n",
    "                    f'image: {masses_balanced.iloc[index].name}\\np: {predicted}; e: {expected}'                   \n",
    "                   )\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1df374",
   "metadata": {},
   "source": [
    "### TRAIN AND EVALUATE MODEL FOR ALL CLASSES (FULLY BALANCED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebad5d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mias_full = hp.full_balance_df_by_severity(mias)\n",
    "all_mias_full"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a874e12d",
   "metadata": {},
   "source": [
    "#### Check Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fb5789",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mias_full.groupby('ab_class').severity.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8251d811",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mias_full.groupby(['ab_class', 'severity']).size().unstack().plot(kind='bar', \n",
    "                                                              stacked=True, \n",
    "                                                              figsize=(10, 8), \n",
    "                                                              xlabel='ABNORMALITIES ONLY', \n",
    "                                                              ylabel='Percentage',\n",
    "                                                              title='SEVERITY BY CLASS');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0529d33d",
   "metadata": {},
   "source": [
    "#### Generate Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60310df",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator = ImageDataGenerator(validation_split=.25, \n",
    "                                    height_shift_range=.10, \n",
    "                                    width_shift_range=.10, \n",
    "                                    rotation_range=30, \n",
    "                                    rescale=1/255.)\n",
    "\n",
    "train_data = data_generator.flow_from_dataframe(all_mias_full, \n",
    "                                                x_col=\"subsample_path\", \n",
    "                                                y_col=\"severity\",\n",
    "                                                class_mode=\"categorical\",\n",
    "                                                target_size=(48,48),\n",
    "                                                subset=\"training\",\n",
    "                                                color_mode=\"grayscale\",\n",
    "                                                shuffle=True)\n",
    "test_data = data_generator.flow_from_dataframe(all_mias_full, \n",
    "                                               x_col=\"subsample_path\", \n",
    "                                               y_col=\"severity\",\n",
    "                                               class_mode=\"categorical\",\n",
    "                                               target_size=(48,48),\n",
    "                                               subset=\"validation\",\n",
    "                                               color_mode=\"grayscale\",\n",
    "                                               shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c4b9da",
   "metadata": {},
   "source": [
    "#### Create Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6963be",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mias = Sequential()\n",
    "# first layer\n",
    "all_mias.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=(48, 48, 1)))\n",
    "all_mias.add(Conv2D(64, kernel_size=(3,3),activation='relu'))\n",
    "all_mias.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "all_mias.add(Conv2D(64, kernel_size=(3,3),activation='relu'))\n",
    "all_mias.add(MaxPool2D(pool_size=(2, 2)))\n",
    "all_mias.add(Dropout(0.25))\n",
    "# Add dense layer to reduce the number of features\n",
    "all_mias.add(Dense(64, activation='relu'))\n",
    "all_mias.add(Dropout(0.25))\n",
    "# flattening results\n",
    "all_mias.add(Flatten())\n",
    "# Dense layer to produce final output\n",
    "all_mias.add(Dense(3, activation='softmax'))\n",
    "# print summary\n",
    "all_mias.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0cb986",
   "metadata": {},
   "source": [
    "#### Visualise the Model's Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e68edf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(all_mias, to_file='convnet.png', show_shapes=True, show_layer_names=True)\n",
    "Image(filename='convnet.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc4e3d8",
   "metadata": {},
   "source": [
    "#### Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6015de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # set optmizer and learning rate\n",
    "adam = Adam(0.001)\n",
    "all_mias.compile(optimizer=adam,\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e220c3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set callbacks\n",
    "early_stopping = EarlyStopping(patience=10_000, restore_best_weights=True)\n",
    "\n",
    "\n",
    "model_check_point = ModelCheckpoint(filepath= './', \n",
    "                                    monitor='val_loss', verbose=1, \n",
    "                                    save_best_only=True,\n",
    "                                    save_weights_only=False, \n",
    "                                    mode='auto', save_freq='epoch')\n",
    "\n",
    "# fit the model\n",
    "hist = all_mias.fit(train_data, \n",
    "                    validation_data=test_data, \n",
    "                    epochs=10_000,\n",
    "                    callbacks=[early_stopping, model_check_point])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7e59c9",
   "metadata": {},
   "source": [
    "#### Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643d7d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions\n",
    "predictions = all_mias.predict(test_data)\n",
    "predicted = [np.argmax(w) for w in predictions]\n",
    "expected = test_data.labels\n",
    "\n",
    "\n",
    "# Evaluation Results\n",
    "loss_value , accuracy = all_mias.evaluate(train_data)\n",
    "\n",
    "print(f'Test loss_value: {loss_value}')\n",
    "print(f'Test accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b874dcf",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec8eb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(expected, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdff96ce",
   "metadata": {},
   "source": [
    "#### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736f4680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B, M or A\n",
    "print(f'Classes: {test_data.class_indices}\\n')\n",
    "print(classification_report(expected, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe20995c",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e11f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_plot = hp.plot_results(hist.history['accuracy'],\n",
    "                               hist.history['val_accuracy'], \n",
    "                               hist.history['loss'], \n",
    "                               hist.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e0914c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter data to the final results dataframe\n",
    "results_all_mias = classification_report(expected, predicted, output_dict=True)\n",
    "# add entry to the final_results\n",
    "all_mias_malignant = results_all_mias['1']\n",
    "all_mias_malignant\n",
    "final_results.loc['all_full_bal'] = (accuracy,\n",
    "                                     all_mias_malignant['precision'], \n",
    "                                     all_mias_malignant['recall'], \n",
    "                                     all_mias_malignant['f1-score'])\n",
    "final_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b2af84",
   "metadata": {},
   "source": [
    "#### Checking Wrong Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c57ccdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking wrong predictions\n",
    "predictions = all_mias.predict(test_data)\n",
    "\n",
    "# check the probabilities for the first sample\n",
    "for index, probability in enumerate(predictions[0]):\n",
    "    print(f'{index}: {probability:.10%}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8269b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = all_mias_full.p_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df31a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_predictions = []\n",
    "\n",
    "for i, (p,e) in enumerate(zip(predictions, test_data.labels)):\n",
    "    predicted, expected = np.argmax(p), np.argmax(e)\n",
    "    # create something to keep the same index from calcifications_balanced\n",
    "    # and wrong predictions\n",
    "    if predicted != expected:\n",
    "        wrong_predictions.append(\n",
    "            (i, images[i], predicted, expected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14404ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(wrong_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4024dbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c,d = wrong_predictions[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeaef8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = all_mias_full.iloc[a].loc['p_matrix'] == b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdca0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.display_probabilities(predictions[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcc7f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, axes = plt.subplots(nrows=5, ncols=6, figsize=(16, 12))\n",
    "\n",
    "for axes, item in zip(axes.ravel(), wrong_predictions):\n",
    "    index, image, predicted, expected = item\n",
    "    axes.imshow(image, cmap=plt.cm.gray_r)\n",
    "    axes.set_title(\n",
    "                    f'image: {all_mias_full.iloc[index].name}\\np: {predicted}; e: {expected}'                   \n",
    "                   )\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00754f50",
   "metadata": {},
   "source": [
    "### TRAIN AND EVALUATE MODEL FOR ALL CLASSES (CLASS BALANCED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b935f519",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mias_bal = hp.balance_df_by_severity(mias)\n",
    "all_mias_bal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3dc97bd",
   "metadata": {},
   "source": [
    "#### Check Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f43d3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mias_bal.groupby('ab_class').severity.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2223892c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mias_bal.groupby(['ab_class', 'severity']).size().unstack().plot(kind='bar', \n",
    "                                                              stacked=True, \n",
    "                                                              figsize=(10, 8), \n",
    "                                                              xlabel='ABNORMALITIES ONLY', \n",
    "                                                              ylabel='Percentage',\n",
    "                                                              title='SEVERITY BY CLASS');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84693a7b",
   "metadata": {},
   "source": [
    "#### Generate Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb52605",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator = ImageDataGenerator(validation_split=.25, \n",
    "                                    height_shift_range=.10, \n",
    "                                    width_shift_range=.10, \n",
    "                                    rotation_range=30, \n",
    "                                    rescale=1/255.)\n",
    "\n",
    "train_data = data_generator.flow_from_dataframe(all_mias_bal, \n",
    "                                                x_col=\"subsample_path\", \n",
    "                                                y_col=\"severity\",\n",
    "                                                class_mode=\"categorical\",\n",
    "                                                target_size=(48,48),\n",
    "                                                subset=\"training\",\n",
    "                                                color_mode=\"grayscale\",\n",
    "                                                shuffle=True)\n",
    "test_data = data_generator.flow_from_dataframe(all_mias_bal, \n",
    "                                               x_col=\"subsample_path\", \n",
    "                                               y_col=\"severity\",\n",
    "                                               class_mode=\"categorical\",\n",
    "                                               target_size=(48,48),\n",
    "                                               subset=\"validation\",\n",
    "                                               color_mode=\"grayscale\",\n",
    "                                               shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75c66a3",
   "metadata": {},
   "source": [
    "#### Create Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95b257e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mias2 = Sequential()\n",
    "# first layer\n",
    "all_mias2.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=(48, 48, 1)))\n",
    "all_mias2.add(Conv2D(64, kernel_size=(3,3),activation='relu'))\n",
    "all_mias2.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "all_mias2.add(Conv2D(64, kernel_size=(3,3),activation='relu'))\n",
    "all_mias2.add(MaxPool2D(pool_size=(2, 2)))\n",
    "all_mias2.add(Dropout(0.25))\n",
    "# Add dense layer to reduce the number of features\n",
    "all_mias2.add(Dense(64, activation='relu'))\n",
    "all_mias2.add(Dropout(0.25))\n",
    "# flattening results\n",
    "all_mias2.add(Flatten())\n",
    "# Dense layer to produce final output\n",
    "all_mias2.add(Dense(3, activation='softmax'))\n",
    "# print summary\n",
    "all_mias2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096cbf5a",
   "metadata": {},
   "source": [
    "#### Visualise the Model's Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeead51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(all_mias2, to_file='convnet.png', show_shapes=True, show_layer_names=True)\n",
    "Image(filename='convnet.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b79743",
   "metadata": {},
   "source": [
    "#### Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f76d93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # set optmizer and learning rate\n",
    "adam = Adam(0.001)\n",
    "all_mias2.compile(optimizer=adam,\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fb9d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set callbacks\n",
    "early_stopping = EarlyStopping(patience=10_000, restore_best_weights=True)\n",
    "\n",
    "\n",
    "model_check_point = ModelCheckpoint(filepath= './', \n",
    "                                    monitor='val_loss', verbose=1, \n",
    "                                    save_best_only=True,\n",
    "                                    save_weights_only=False, \n",
    "                                    mode='auto', save_freq='epoch')\n",
    "\n",
    "# fit the model\n",
    "hist = all_mias2.fit(train_data, \n",
    "                    validation_data=test_data, \n",
    "                    epochs=10_000,\n",
    "                    callbacks=[early_stopping, model_check_point])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145ed23a",
   "metadata": {},
   "source": [
    "#### Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ce66bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions\n",
    "predictions = all_mias2.predict(test_data)\n",
    "predicted = [np.argmax(w) for w in predictions]\n",
    "expected = test_data.labels\n",
    "\n",
    "# Evaluation Results\n",
    "loss_value , accuracy = all_mias2.evaluate(train_data)\n",
    "\n",
    "print(f'Test loss_value: {loss_value}')\n",
    "print(f'Test accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c18f34",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99bf873",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(expected, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4c140e",
   "metadata": {},
   "source": [
    "#### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a07507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B, M or A\n",
    "print(f'Classes: {test_data.class_indices}\\n')\n",
    "print(classification_report(expected, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ea283b",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a9413a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_plot = hp.plot_results(hist.history['accuracy'],\n",
    "                               hist.history['val_accuracy'], \n",
    "                               hist.history['loss'], \n",
    "                               hist.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606a2f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter data to the final results dataframe\n",
    "results_all_mias2 = classification_report(expected, predicted, output_dict=True)\n",
    "# add entry to the final_results\n",
    "all_mias_malignant2 = results_all_mias2['1']\n",
    "all_mias_malignant2\n",
    "final_results.loc['all_bal'] = (accuracy,\n",
    "                                all_mias_malignant2['precision'], \n",
    "                                all_mias_malignant2['recall'], \n",
    "                                all_mias_malignant2['f1-score'])\n",
    "final_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576a7c56",
   "metadata": {},
   "source": [
    "#### Checking Wrong Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b585ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking wrong predictions\n",
    "predictions = all_mias2.predict(test_data)\n",
    "wrong_predictions = []\n",
    "images = all_mias_bal.p_matrix\n",
    "\n",
    "for i, (p,e) in enumerate(zip(predictions, test_data.labels)):\n",
    "    predicted, expected = np.argmax(p), np.argmax(e)\n",
    "    if predicted != expected:\n",
    "        wrong_predictions.append(\n",
    "            (i, images[i], predicted, expected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8181edf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(wrong_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795d02c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c,d = wrong_predictions[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0484579b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = all_mias_bal.iloc[a].loc['p_matrix'] == b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720ef596",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfb1513",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.display_probabilities(predictions[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4354f96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, axes = plt.subplots(nrows=5, ncols=6, figsize=(16, 12))\n",
    "\n",
    "for axes, item in zip(axes.ravel(), wrong_predictions):\n",
    "    index, image, predicted, expected = item\n",
    "    axes.imshow(image, cmap=plt.cm.gray_r)\n",
    "    axes.set_title(\n",
    "                    f'image: {all_mias_bal.iloc[index].name}\\np: {predicted}; e: {expected}'                   \n",
    "                   )\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d06211c",
   "metadata": {},
   "source": [
    "### Plot Final Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b09e85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results.plot(kind='barh', figsize=(7, 9), legend={'reverse'} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28a2f63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
